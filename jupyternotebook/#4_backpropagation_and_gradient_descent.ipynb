{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f45253cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41fab516",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([1,2,3,4,5],dtype=torch.float32)\n",
    "y=torch.tensor([2,4,6.2,7.6,9.8],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "addaa45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build linear reg\n",
    "def linear_reg(x,w,b):\n",
    "    return x*w+b\n",
    "\n",
    "def square_loss(y_hat,y):\n",
    "    return torch.mean((y_hat-y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c6a1112",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_time=50\n",
    "lr=0.01\n",
    "w=torch.tensor(0,dtype=torch.float32,requires_grad=True)\n",
    "b=torch.tensor(0,dtype=torch.float32,requires_grad=True)\n",
    "\n",
    "for i in range(iter_time):\n",
    "    # compute predict value\n",
    "    y_hat=linear_reg(x,w,b)\n",
    "    \n",
    "    # compute loss\n",
    "    loss=square_loss(y_hat,y)\n",
    "    \n",
    "    # compute grad\n",
    "    loss.backward()\n",
    "    \n",
    "    # update grad\n",
    "    with torch.no_grad():\n",
    "        #w.sub_(lr*w.grad)\n",
    "        w-=w.grad*lr\n",
    "        b-=b.grad*lr\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc656e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not use w=w-lr*w.grad, because now w will be assign as a new tensor which requires_grad=False\n",
    "# instead, use w-=lr*w.grad or w.sub_(lr*w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa1a4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general pipeline\n",
    "# 1. design model (input,output)\n",
    "# 2. construct the loss and optimizer \n",
    "# 3. training loop\n",
    "#      - forward pass: compute prediction\n",
    "#      - backward pass: gradients\n",
    "#      - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c59e496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import MSELoss,Linear\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac2bf0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([[1],[2],[3],[4],[5]],dtype=torch.float32)\n",
    "y=torch.tensor([[2],[4],[6.2],[7.6],[9.8]],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bc6186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self,feature_n):\n",
    "        super().__init__() # initalize superclass.\n",
    "        self.linear_layer=Linear(feature_n,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y = self.linear_layer(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18ef6642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(41.6811, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(1.4522, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.1027, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0542, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0533, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0517, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0494, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0487, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0481, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0474, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0462, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0450, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0440, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0412, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0404, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([5, 1]) torch.Size([5, 1])\n",
      "tensor(0.0396, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sample_n, feature_n = x.shape\n",
    "iter_time=30\n",
    "learning_rate=0.05\n",
    "\n",
    "# construct model\n",
    "model = LinearRegression(feature_n)\n",
    "# construct optimizer\n",
    "loss_func = MSELoss() \n",
    "optimizer = SGD(model.parameters(),lr=learning_rate)\n",
    "# training loop\n",
    "for i in range(iter_time):\n",
    "    y_pred = model(x)\n",
    "    print(y_pred.shape,y.shape)\n",
    "    loss = loss_func(y_pred,y)\n",
    "    loss.backward()\n",
    "    print(loss)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32edf111",
   "metadata": {},
   "source": [
    "### loss function\n",
    "1. All loss functions are stored in torch.nn module.\n",
    "2. How to perform it:\n",
    "    - First we need to create an instance (e.g. loss=torch.nn.MSELoss())\n",
    "    - Next, call the loss object by passing into predict val and target val. (e.g. loss(y_hat,y))\n",
    "    - Last, apply backward method to perform back prop (e.g. loss.backward())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671f1c85",
   "metadata": {},
   "source": [
    "### optimizer\n",
    "1. to use torch.optim you have to construct an optimizer object. (e.g. torch.optim.SGD(parameters, defaults))\n",
    "2. To construct an Optimizer you have to give it an iterable containing the parameters (all should be Variable s) to optimize.\n",
    "3. All optimizers implement a step() method, that updates the parameters. (This should be done after loss.backward())\n",
    "4. Use optimizer.zero_grad() to set the gradients to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f9be5a",
   "metadata": {},
   "source": [
    "### Build a model\n",
    "1. the model is inherited from class nn.Module\n",
    "2. Implement the model by designing __init__ and forward methods.\n",
    "3. call the model will invoke .forward() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b634fa19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:virtualenv] *",
   "language": "python",
   "name": "conda-env-virtualenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
